# 术语
## NLP
NLP是Natural Language Processing的缩写,汉语翻译为自然语言处理。它是一门研究如何让机器解析、理解和生成人类语言的学科。

NLP的主要目标包括:
* 文本分析:进行词法分析、句法分析、语义分析等,理解文本的结构和含义。
* 机器翻译:使机器能够将一种语言自动翻译成另一种语言。
* 问答系统:让机器能够自动回答人类提出的问题。
* 语音识别:使机器听懂人类语音,转化为文本。
* 自然语言生成:自动生成类似人类语言的文本。
* 信息提取:从文本中提取结构化信息。
* sentiment analysis:分析文本的情感极性,是否正面或负面。
* 语音合成:由机器自动生成人类语音。
*  语义分析:分析文本的语义,得到文本的完整含义。

NLP技术广泛应用于语音助手、机器翻译、搜索引擎、文档摘要、sentiment分析等领域。这门学科正快速发展,有望使机器更好地处理和理解人类语言。

## Transformer 
Transformer 是一种基于注意力机制(Attention Mechanism)的神经网络模型,被广泛用于自然语言处理(NLP)领域。

## RNN 和 CNN
RNN(循环神经网络)和CNN(卷积神经网络)都是神经网络中的重要模型结构,两者都可以用于处理序列数据,但也存在一些区别:

1. RNN能够处理变长序列,对序列具有“记忆”能力,当前状态与前序状态相关。而CNN更适合处理固定长度序列,对序列没有记忆能力。
2. RNN在处理远距离依赖关系上效果较好,而CNN的感受野有限,对远距离依赖关系建模较弱。
3. RNN训练较为复杂,容易产生梯度消失/爆炸问题。CNN训练简单且易于并行计算。
4. RNN参数共享,对序列各位置计算相同。CNN通过卷积核提取局部特征,不同卷积核可学习不同特征。
5. RNN常用于语音识别、机器翻译、语言模型等需要顺序处理的任务。CNN常用于图像处理、文本分类等静态数据处理任务。
6. RNN代表模型包括GRU、LSTM等。CNN典型模型包括LeNet、AlexNet等。

总体来说,RNN对序列数据建模更加自然,但CNN计算效率更高、训练更容易。需要根据具体任务选择使用RNN或CNN模型。当前一些模型也结合使用RNN和CNN的优点,形成更强大的模型。

## Prompt
前置提示词。也简称为 提示题。

